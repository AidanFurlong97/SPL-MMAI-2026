{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",

    "def parse_coordinate(val):\n",
    "    if isinstance(val, str):\n",
    "        clean_val = val.replace('[', '').replace(']', '').replace(',', ' ').replace('\\n', ' ').strip()\n",
    "        return np.fromstring(clean_val, sep=' ')\n",
    "    return np.array(val)\n",
    "\n",
    "def preprocess_dataset(df):\n",
    "    \"\"\"\n",
    "    Converts the DataFrame of lists into a 3D Numpy Tensor.\n",
    "    Output Shape: (n_samples, 240, 207)\n",
    "    \"\"\"\n",
    "    n_samples = len(df)\n",
    "    n_frames = 240\n",
    "    \n",
    "    # identify feature columns (excluding any ID/Label columns)\n",
    "    # assuming all columns that end in _x, _y, _z are features\n",
    "    feature_cols = [c for c in df.columns if c.endswith(('_x', '_y', '_z'))]\n",
    "    n_features = len(feature_cols) # Should be 207\n",
    "    \n",
    "    print(f\"Processing {n_samples} samples with {n_features} features over {n_frames} frames...\")\n",
    "    \n",
    "    # Initialize empty 3D tensor\n",
    "    X = np.zeros((n_samples, n_frames, n_features))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        row = df.iloc[i]\n",
    "        for j, col_name in enumerate(feature_cols):\n",
    "            # Parse the list of 240 floats\n",
    "            val = parse_coordinate(row[col_name])\n",
    "            \n",
    "            # Safety check for length\n",
    "            if len(val) == n_frames:\n",
    "                X[i, :, j] = val\n",
    "            else:\n",
    "                # Handle edge case where a list might be short (pad with zeros?)\n",
    "                # For now, just truncating or padding to fit\n",
    "                valid_len = min(len(val), n_frames)\n",
    "                X[i, :valid_len, j] = val[:valid_len]\n",
    "                \n",
    "    return X, feature_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 345 samples with 207 features over 240 frames...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(345, 240, 207)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATA EXAMPLE\n",
    "df = pd.read_csv('train.csv')\n",
    "X_train_unclean, feature_names = preprocess_dataset(df)\n",
    "\n",
    "# X_train.shape should now be (345, 240, 207)\n",
    "X_train_unclean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nans(X):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the 3D tensor (Samples, Time, Features).\n",
    "    Strategy: \n",
    "    1. Forward Fill (propagate last valid observation forward).\n",
    "    2. Backward Fill (use next valid observation to fill initial NaNs).\n",
    "    3. Fill remaining (if a joint is missing for the entire shot) with 0.\n",
    "    \"\"\"\n",
    "    # Check if there are actually NaNs to avoid unnecessary processing\n",
    "    if not np.isnan(X).any():\n",
    "        print(\"No NaNs found. Data is clean.\")\n",
    "        return X\n",
    "\n",
    "    print(f\"NaNs detected. Cleaning {X.shape[0]} samples...\")\n",
    "    \n",
    "    # Iterate through every sample (shot)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Extract the (240 frames x 207 features) matrix for this shot\n",
    "        sample_data = X[i, :, :]\n",
    "        \n",
    "        # Convert to Pandas DataFrame to use its fill methods\n",
    "        df_sample = pd.DataFrame(sample_data)\n",
    "        \n",
    "        # 1. Forward Fill (takes care of NaNs in the middle or end)\n",
    "        df_sample = df_sample.ffill(axis=0)\n",
    "        \n",
    "        # 2. Backward Fill (takes care of NaNs at the very start, frame 0)\n",
    "        df_sample = df_sample.bfill(axis=0)\n",
    "        \n",
    "        # 3. Final safety net: If a column is 100% NaN, fill with 0\n",
    "        df_sample = df_sample.fillna(0.0)\n",
    "        \n",
    "        # Assign the cleaned data back to the numpy array\n",
    "        X[i, :, :] = df_sample.values\n",
    "    \n",
    "\n",
    "    # Double check\n",
    "    assert not np.isnan(X).any(), \"Error: NaNs still exist!\"\n",
    "    print(\"Cleaning complete.\")\n",
    "\n",
    "    return X\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# USAGE\n",
    "# ---------------------------------------------------------\n",
    "# Assuming you already ran preprocess_dataset and have X_train\n",
    "# X_train, feature_cols = preprocess_dataset(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_skeleton(X, feature_cols):\n",
    "    \"\"\"\n",
    "    Subtracts the mid_hip position from all other joints for every frame.\n",
    "    Assumes layout: X shape (Samples, Frames, Features)\n",
    "    \"\"\"\n",
    "    # 1. Identify indices for mid_hip x, y, z\n",
    "    try:\n",
    "        hip_x_idx = feature_cols.index('mid_hip_x')\n",
    "        hip_y_idx = feature_cols.index('mid_hip_y')\n",
    "        hip_z_idx = feature_cols.index('mid_hip_z')\n",
    "    except ValueError:\n",
    "        print(\"Error: mid_hip columns not found!\")\n",
    "        return X\n",
    "\n",
    "    print(\"Centering skeleton relative to mid_hip...\")\n",
    "    \n",
    "    # X shape: (N, 240, 207)\n",
    "    X_centered = X.copy()\n",
    "    \n",
    "    # We need to iterate over features in triplets (x, y, z)\n",
    "    # This assumes features are ordered: nose_x, nose_y, nose_z, ...\n",
    "    # A safer way is to loop through columns and find matching dimension\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        if col.endswith('_x'):\n",
    "            # Subtract hip_x from this column\n",
    "            X_centered[:, :, i] -= X[:, :, hip_x_idx]\n",
    "        elif col.endswith('_y'):\n",
    "            # Subtract hip_y from this column\n",
    "            X_centered[:, :, i] -= X[:, :, hip_y_idx]\n",
    "        elif col.endswith('_z'):\n",
    "            # Subtract hip_z from this column\n",
    "            X_centered[:, :, i] -= X[:, :, hip_z_idx]\n",
    "    \n",
    "    print(\"Centering complete.\")\n",
    "    return X_centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def add_participant_features(X_3d, df, encoder=None):\n",
    "    \"\"\"\n",
    "    1. One-Hot Encodes the participant_id.\n",
    "    2. Repeats this encoding 240 times (for each frame).\n",
    "    3. Appends it to the skeleton data.\n",
    "    \n",
    "    Returns: \n",
    "        X_combined: Shape (N, 240, 207 + n_participants)\n",
    "        encoder: The fitted encoder object\n",
    "    \"\"\"\n",
    "    # 1. Extract IDs and Reshape for Sklearn (requires 2D array)\n",
    "    # Ensure we fill NaNs if any exist (though IDs shouldn't have NaNs)\n",
    "    ids = df['participant_id'].fillna('Unknown').values.reshape(-1, 1)\n",
    "    \n",
    "    if encoder is None:\n",
    "        # TRAIN MODE: Fit the encoder on training IDs\n",
    "        # handle_unknown='ignore' ensures if Test has a new person, it becomes all 0s (safe)\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        ids_encoded = encoder.fit_transform(ids)\n",
    "    else:\n",
    "        # TEST MODE: Transform using existing logic\n",
    "        ids_encoded = encoder.transform(ids)\n",
    "        \n",
    "    # ids_encoded shape is (N_samples, N_participants) e.g., (345, 10)\n",
    "    \n",
    "    # 2. Broadcast (Repeat) across time steps\n",
    "    n_samples = X_3d.shape[0]\n",
    "    n_frames = X_3d.shape[1] # 240\n",
    "    n_id_features = ids_encoded.shape[1]\n",
    "    \n",
    "    # Create a 3D block of IDs: (N, 240, N_participants)\n",
    "    # We use np.tile to repeat the ID vector for every frame\n",
    "    ids_3d = np.tile(ids_encoded[:, np.newaxis, :], (1, n_frames, 1))\n",
    "    \n",
    "    # 3. Concatenate with Skeleton Data\n",
    "    # X_3d is (N, 240, 207)\n",
    "    # Combined is (N, 240, 207 + N_participants)\n",
    "    X_combined = np.concatenate([X_3d, ids_3d], axis=2)\n",
    "    \n",
    "    return X_combined, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIPELINE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def processing_pipeline_with_id(df, skel_scaler=None, id_encoder=None):\n",
    "    # 1. Preprocess & Clean\n",
    "    X_3d, feature_names = preprocess_dataset(df)\n",
    "    X_clean = clean_nans(X_3d)\n",
    "    X_centered = center_skeleton(X_clean, feature_names)\n",
    "    \n",
    "    # 2. Scale Skeleton (StandardScaler)\n",
    "    N, T, F = X_centered.shape\n",
    "    X_flat = X_centered.reshape(N * T, F)\n",
    "    \n",
    "    if skel_scaler is None:\n",
    "        skel_scaler = StandardScaler()\n",
    "        X_scaled_flat = skel_scaler.fit_transform(X_flat)\n",
    "    else:\n",
    "        X_scaled_flat = skel_scaler.transform(X_flat)\n",
    "        \n",
    "    X_skel_final = X_scaled_flat.reshape(N, T, F)\n",
    "\n",
    "    # 3. Add Participant ID\n",
    "    X_final, id_encoder = add_participant_features(X_skel_final, df, id_encoder)\n",
    "\n",
    "    return X_final, skel_scaler, id_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. BUILD THE BASE MODEL (Regression)\n",
    "# ---------------------------------------------------------\n",
    "def create_base_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Layer 1: LSTM to process the time-series\n",
    "    model.add(layers.LSTM(64, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Layer 2: Dense Layer\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Layer 3: Output Layer (Linear for regression)\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. TRAIN MODELS FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def train_all_models(y_train_df, X_train, target_columns=None, epochs=20, batch_size=16):\n",
    "    \"\"\"\n",
    "    Trains separate regression models for each target column.\n",
    "    \n",
    "    Args:\n",
    "        y_train_df: DataFrame containing ONLY the target labels (or all labels).\n",
    "        X_train: The preprocessed 3D numpy array (Samples, Frames, Features).\n",
    "        target_columns: List of strings (column names to predict).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default targets\n",
    "    if target_columns is None:\n",
    "        target_columns = ['angle', 'depth', 'left_right']\n",
    "        \n",
    "    # Infer input shape\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    trained_models = {}\n",
    "\n",
    "    for target in target_columns:\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        print(f\"Training model for target: {target}\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # 1. Get the target data (Y) for this specific column\n",
    "        # We use the passed 'y_train_df' instead of 'df'\n",
    "        if len(y_train_df) != len(X_train):\n",
    "            print(f\"Warning: y_train_df has {len(y_train_df)} rows but X_train has {len(X_train)}. Truncating.\")\n",
    "            # Use a different variable name for the numpy array to avoid overwriting the argument\n",
    "            current_y = y_train_df[target].values[:len(X_train)]\n",
    "        else:\n",
    "            current_y = y_train_df[target].values\n",
    "        \n",
    "        # 2. Create fresh model\n",
    "        model = create_base_model(input_shape)\n",
    "        \n",
    "        # 3. Train\n",
    "        history = model.fit(\n",
    "            X_train, \n",
    "            current_y,  # <--- Use the specific numpy array for this target\n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 4. Save\n",
    "        trained_models[f\"shot_{target}\"] = model\n",
    "        \n",
    "        final_mae = history.history['mae'][-1]\n",
    "        print(f\"--> Done. Final MAE for {target}: {final_mae:.4f}\")\n",
    "        \n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Processing Train...\n",
      "Processing 345 samples with 207 features over 240 frames...\n",
      "NaNs detected. Cleaning 345 samples...\n",
      "Cleaning complete.\n",
      "Centering skeleton relative to mid_hip...\n",
      "Centering complete.\n",
      "New Input Shape: (345, 240, 212)\n",
      "\n",
      "========================================\n",
      "Training model for target: angle\n",
      "========================================\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidanfurlong/Downloads/spl-utspan-data-challenge-2026/.venv/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 2165.0178 - mae: 46.2703 - val_loss: 1465.6930 - val_mae: 38.0796\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1991.9305 - mae: 44.4266 - val_loss: 1167.6091 - val_mae: 33.9515\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1583.5510 - mae: 39.5602 - val_loss: 798.8459 - val_mae: 27.9586\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1086.0554 - mae: 32.5109 - val_loss: 325.1088 - val_mae: 17.5688\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 534.3041 - mae: 22.1649 - val_loss: 64.4316 - val_mae: 7.2824\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 155.8820 - mae: 10.8231 - val_loss: 25.0379 - val_mae: 3.4963\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 72.9430 - mae: 6.8642 - val_loss: 63.9685 - val_mae: 6.8925\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 68.3348 - mae: 6.7617 - val_loss: 65.3067 - val_mae: 6.9668\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 60.2753 - mae: 6.1037 - val_loss: 61.5949 - val_mae: 6.8218\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 44.8030 - mae: 5.3091 - val_loss: 37.8919 - val_mae: 4.9465\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 55.6974 - mae: 5.9814 - val_loss: 63.7169 - val_mae: 7.0466\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 61.3667 - mae: 6.2327 - val_loss: 42.8880 - val_mae: 5.3973\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 48.0366 - mae: 5.6916 - val_loss: 30.6540 - val_mae: 4.1582\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 39.6365 - mae: 5.0639 - val_loss: 31.0753 - val_mae: 4.2009\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 41.6009 - mae: 4.9032 - val_loss: 36.9312 - val_mae: 4.8069\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 40.9663 - mae: 5.0778 - val_loss: 37.7653 - val_mae: 4.8740\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 43.7448 - mae: 5.2296 - val_loss: 34.5140 - val_mae: 4.4263\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 50.4308 - mae: 5.4571 - val_loss: 30.4322 - val_mae: 4.2575\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 42.9609 - mae: 5.5317 - val_loss: 23.9715 - val_mae: 3.5968\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 36.6794 - mae: 4.8630 - val_loss: 20.7089 - val_mae: 3.1926\n",
      "--> Done. Final MAE for angle: 5.0658\n",
      "\n",
      "========================================\n",
      "Training model for target: depth\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 109.8482 - mae: 9.5386 - val_loss: 105.1096 - val_mae: 8.5748\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 85.1429 - mae: 8.3571 - val_loss: 79.1638 - val_mae: 7.1237\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 49.2913 - mae: 6.0668 - val_loss: 68.0578 - val_mae: 6.4400\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 25.0762 - mae: 4.1048 - val_loss: 73.2639 - val_mae: 6.6902\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 15.7205 - mae: 3.1074 - val_loss: 71.8684 - val_mae: 6.6390\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 19.0162 - mae: 3.2998 - val_loss: 68.8078 - val_mae: 6.4152\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 19.0875 - mae: 3.4756 - val_loss: 66.3709 - val_mae: 6.3112\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 18.3550 - mae: 3.4308 - val_loss: 62.4807 - val_mae: 6.1129\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 16.8264 - mae: 3.1481 - val_loss: 63.0236 - val_mae: 6.1149\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 17.1794 - mae: 3.3087 - val_loss: 64.3095 - val_mae: 6.2323\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 18.0750 - mae: 3.3144 - val_loss: 63.4801 - val_mae: 6.2004\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 17.3797 - mae: 3.3706 - val_loss: 65.5344 - val_mae: 6.2868\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 14.8624 - mae: 3.0053 - val_loss: 69.4611 - val_mae: 6.6724\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 16.7648 - mae: 3.2181 - val_loss: 72.6989 - val_mae: 6.6384\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 16.4374 - mae: 3.1069 - val_loss: 74.2719 - val_mae: 6.7457\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 16.9091 - mae: 3.3009 - val_loss: 75.8039 - val_mae: 6.6794\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 14.6763 - mae: 3.0123 - val_loss: 76.2892 - val_mae: 6.6915\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 12.9958 - mae: 2.8817 - val_loss: 74.6664 - val_mae: 6.7117\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 14.5637 - mae: 3.0376 - val_loss: 77.6195 - val_mae: 6.8843\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 15.3529 - mae: 3.0703 - val_loss: 76.5293 - val_mae: 6.7828\n",
      "--> Done. Final MAE for depth: 3.0317\n",
      "\n",
      "========================================\n",
      "Training model for target: left_right\n",
      "========================================\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 15.4455 - mae: 3.1505 - val_loss: 18.3590 - val_mae: 3.5425\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 12.9410 - mae: 2.7574 - val_loss: 15.2964 - val_mae: 3.2079\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 12.4102 - mae: 2.6723 - val_loss: 16.9045 - val_mae: 3.3910\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 11.0311 - mae: 2.6113 - val_loss: 16.4944 - val_mae: 3.3588\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 11.9970 - mae: 2.7031 - val_loss: 16.2111 - val_mae: 3.3190\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 12.1500 - mae: 2.7294 - val_loss: 15.7755 - val_mae: 3.2650\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 10.8968 - mae: 2.5818 - val_loss: 14.5583 - val_mae: 3.1498\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 10.3475 - mae: 2.5168 - val_loss: 14.5642 - val_mae: 3.1359\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 11.1602 - mae: 2.6986 - val_loss: 16.6342 - val_mae: 3.3883\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 11.1009 - mae: 2.5806 - val_loss: 16.8345 - val_mae: 3.3956\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 11.5317 - mae: 2.6062 - val_loss: 14.5062 - val_mae: 3.1228\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 9.7884 - mae: 2.4848 - val_loss: 13.5440 - val_mae: 2.9904\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 8.7271 - mae: 2.2919 - val_loss: 13.3815 - val_mae: 2.9699\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 9.1003 - mae: 2.2901 - val_loss: 13.9888 - val_mae: 3.0082\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 10.8022 - mae: 2.5472 - val_loss: 13.8639 - val_mae: 2.9769\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 9.8684 - mae: 2.3816 - val_loss: 12.5800 - val_mae: 2.8437\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 9.3497 - mae: 2.3701 - val_loss: 16.9712 - val_mae: 3.4249\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 11.4860 - mae: 2.6751 - val_loss: 14.6400 - val_mae: 3.1624\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 10.0806 - mae: 2.4411 - val_loss: 13.4304 - val_mae: 3.0168\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 9.2845 - mae: 2.3953 - val_loss: 13.0778 - val_mae: 2.9633\n",
      "--> Done. Final MAE for left_right: 2.3607\n",
      "loading test.csv...\n",
      "Processing Test...\n",
      "Processing 113 samples with 207 features over 240 frames...\n",
      "NaNs detected. Cleaning 113 samples...\n",
      "Cleaning complete.\n",
      "Centering skeleton relative to mid_hip...\n",
      "Centering complete.\n",
      "\n",
      "All models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# LOAD RAW DATA\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Load your training CSV\n",
    "print(\"Loading train.csv...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# --- TRAIN ---\n",
    "print(\"Processing Train...\")\n",
    "# Pass None for both scalers to create them\n",
    "X_train_final, my_skel_scaler, my_id_encoder = processing_pipeline_with_id(\n",
    "    train_df, \n",
    "    skel_scaler=None, \n",
    "    id_encoder=None\n",
    ")\n",
    "\n",
    "print(f\"New Input Shape: {X_train_final.shape}\") \n",
    "# Shape will be larger now! e.g., (345, 240, 207 + NumberOfParticipants)\n",
    "\n",
    "# Train your models exactly as before (The function handles the new shape automatically)\n",
    "trained_models = train_all_models(train_df, X_train_final)\n",
    "\n",
    "\n",
    "\n",
    "# --- TEST ---\n",
    "\n",
    "print('loading test.csv...')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(\"Processing Test...\")\n",
    "# Pass the scalers/encoders we just learned\n",
    "X_test_final, _, _ = processing_pipeline_with_id(\n",
    "    test_df, \n",
    "    skel_scaler=my_skel_scaler, \n",
    "    id_encoder=my_id_encoder\n",
    ")\n",
    "\n",
    "# Predict...\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test.csv...\n",
      "Processing 113 samples with 207 features over 240 frames...\n",
      "NaNs detected. Cleaning 113 samples...\n",
      "Cleaning complete.\n",
      "Centering skeleton relative to mid_hip...\n",
      "Centering complete.\n",
      "Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# STEP 4: GENERATE SUBMISSION (Immediately after training)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Loading test.csv...\")\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# A. Process Test Data using the SAME scaler from Step 2\n",
    "X_test_final, _, _ = processing_pipeline_with_id(\n",
    "    test_df, \n",
    "    skel_scaler=my_skel_scaler, \n",
    "    id_encoder=my_id_encoder)\n",
    "\n",
    "# B. Generate Predictions & Scale to 0-1\n",
    "submission_data = {'id': test_df['id']}\n",
    "\n",
    "# Manual Scaler Params (from your competition rules)\n",
    "scaling_params = {\n",
    "    'angle':      {'min': 30,  'max': 60},\n",
    "    'depth':      {'min': -12, 'max': 30},\n",
    "    'left_right': {'min': -16, 'max': 16}\n",
    "}\n",
    "\n",
    "tasks = [\n",
    "    {'name': 'angle',      'col': 'scaled_angle',      'model_key': 'shot_angle'},\n",
    "    {'name': 'depth',      'col': 'scaled_depth',      'model_key': 'shot_depth'},\n",
    "    {'name': 'left_right', 'col': 'scaled_left_right', 'model_key': 'shot_left_right'}\n",
    "]\n",
    "\n",
    "for task in tasks:\n",
    "    model = trained_models[task['model_key']]\n",
    "    \n",
    "    # Predict raw value (e.g. 45 degrees)\n",
    "    raw_preds = model.predict(X_test_final, verbose=0).flatten()\n",
    "    \n",
    "    # Scale to 0-1 range\n",
    "    p = scaling_params[task['name']]\n",
    "    scaled_preds = (raw_preds - p['min']) / (p['max'] - p['min'])\n",
    "    \n",
    "    # Clip and Save\n",
    "    submission_data[task['col']] = np.clip(scaled_preds, 0, 1)\n",
    "\n",
    "# C. Save\n",
    "pd.DataFrame(submission_data).to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
